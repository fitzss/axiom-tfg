# ── axiom-tfg environment variables ──────────────────────────────────────
# Copy this file to .env and fill in real values.
#   cp .env.example .env

# Google Gemini API key (optional).
# When set, the AI Assistant panel is enabled in the web UI.
# Get a key at https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=

# Public base URL (optional).
# When set, evidence_url in API responses becomes an absolute URL.
# Example: https://axiom.example.com  (no trailing slash)
AXIOM_PUBLIC_BASE_URL=

# ── AI configuration ────────────────────────────────────────────────────

# AI provider: "gemini" (default), "openai" (Groq/Together/OpenRouter), or "none".
AXIOM_AI_PROVIDER=gemini

# Default Gemini model for generation and explanation.
AXIOM_GEMINI_MODEL_DEFAULT=gemini-2.0-flash

# Comma-separated allowlist of models the UI can select.
# If unset, uses: gemini-2.0-flash, gemini-2.0-flash-lite, gemini-1.5-flash, gemini-1.5-pro
# AXIOM_GEMINI_MODELS_ALLOWLIST=gemini-2.0-flash,gemini-1.5-flash

# ── OpenAI-compatible provider (Groq, Together, OpenRouter, etc.) ──────
# Set AXIOM_AI_PROVIDER=openai and fill in these values.
# Default base_url points to Groq — change for other providers.

# AXIOM_OPENAI_BASE_URL=https://api.groq.com/openai/v1
# AXIOM_OPENAI_API_KEY=
# AXIOM_OPENAI_MODEL_DEFAULT=llama-3.3-70b-versatile
# AXIOM_OPENAI_MODELS_ALLOWLIST=llama-3.3-70b-versatile,llama-3.1-8b-instant,mixtral-8x7b-32768,gemma2-9b-it

# ── Demo fallback ─────────────────────────────────────────────────────

# Demo fallback mode (recommended for hackathon demos).
# When "true", AI features work even without an API key by using a
# local deterministic generator. Also catches quota errors gracefully.
# Set to "true" for demo-proof operation.
AXIOM_AI_DEMO_FALLBACK=false
